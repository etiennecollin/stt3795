@inproceedings{collinTP2ApprentissageMachine2024,
  title = {TP2 - Apprentissage machine},
  booktitle = {IFT3335 - Intelligence artificielle : introduction},
  author = {Collin, Etienne and Dabilgou, Angela and Gilles-Lesage, Roman},
  date = {2024-04-27},
  pages = {8},
  publisher = {Université de Montréal},
  location = {Montréal, QC, Canada},
  abstract = {Dans le cadre du cours d'introduction à l'intelligence artificielle, nous avons travaillé sur une multitude d'algorithmes d'apprentissage supervisé et non-supervisé. Ce rapport porte sur la comparaison de quelques de ces techniques lorsqu'appliquées à la tâche suivante: analyser une banque de tweets et déterminer automatiquement si chaque tweet est offensant ou non.},
  langid = {french}
}

@inproceedings{dolanAutomaticallyConstructingCorpus2005,
  title = {Automatically {{Constructing}} a {{Corpus}} of {{Sentential Paraphrases}}},
  booktitle = {Proceedings of the {{Third International Workshop}} on {{Paraphrasing}} ({{IWP2005}})},
  author = {Dolan, William B. and Brockett, Chris},
  date = {2005},
  url = {https://aclanthology.org/I05-5002},
  urldate = {2024-04-28},
  eventtitle = {{{IJCNLP}} 2005},
  langid = {english},
  file = {/Users/etiennecollin/Documents/Zotero/storage/S59GAX6N/Dolan and Brockett - 2005 - Automatically Constructing a Corpus of Sentential .pdf}
}

@online{esExploratoryDataAnalysis2022,
  title = {Exploratory {{Data Analysis}} for {{Natural Language Processing}}: {{A Complete Guide}} to {{Python Tools}}},
  shorttitle = {Exploratory {{Data Analysis}} for {{Natural Language Processing}}},
  author = {ES, Shahul},
  date = {2022-07-21T09:30:43+00:00},
  url = {https://neptune.ai/blog/exploratory-data-analysis-natural-language-processing-tools},
  urldate = {2024-04-29},
  abstract = {Explore NLP EDA with Python tools: learn about text statistics, ngrams, topic modeling with pyLDAvis, sentiment analysis, and more},
  langid = {english},
  organization = {neptune.ai},
  file = {/Users/etiennecollin/Documents/Zotero/storage/V5Z7G3SV/exploratory-data-analysis-natural-language-processing-tools.html}
}

@online{GensimTopicModelling2022,
  type = {Documentation},
  title = {Gensim: Topic Modelling for Humans},
  date = {2022-12-21},
  url = {https://radimrehurek.com/gensim/models/doc2vec.html},
  urldate = {2024-04-28},
  abstract = {Efficient topic modelling in Python},
  langid = {english},
  organization = {Gensim},
  file = {/Users/etiennecollin/Documents/Zotero/storage/SXNEBQHX/doc2vec.html}
}

@online{iyerFirstQuoraDataset,
  title = {First {{Quora Dataset Release}}: {{Question Pairs}}},
  shorttitle = {First {{Quora Dataset Release}}},
  author = {Iyer, Shankar and Dandekar, Nikhil and Csernai, Kornél},
  url = {https://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs},
  urldate = {2024-04-28},
  abstract = {Today, we are excited to announce the first in what we plan to be a series of public dataset releases. Our dataset releases will be oriented around various problems of relevance to Quora and will give researchers in diverse areas such as...},
  langid = {english},
  organization = {QuoraData},
  file = {/Users/etiennecollin/Documents/Zotero/storage/NSG6EBIW/First-Quora-Dataset-Release-Question-Pairs.html}
}

@online{ladepecheMangeEnfantsOu2018,
  type = {News},
  title = {"On mange, les enfants" ou "on mange les enfants" les pièges du français à la loupe},
  author = {{LaDepeche}},
  date = {2018-02-25},
  url = {https://www.ladepeche.fr/article/2018/02/25/2748992-mange-enfants-mange-enfants-pieges-francais-loupe.html},
  urldate = {2024-04-29},
  abstract = {(AFP) - Tremblez "mots employés de travers", "locutions creuses et verbeuses", "clichés pénibles" et "néologismes malvenus"... Pour déjouer les pièges du français, "Les 300 plus belles fautes à ne pas faire et autres...},
  langid = {french},
  organization = {ladepeche.fr},
  file = {/Users/etiennecollin/Documents/Zotero/storage/TF3HSQ2K/2748992-mange-enfants-mange-enfants-pieges-francais-loupe.html}
}

@online{LinguisticFeaturesSpaCy,
  type = {Documentation},
  title = {Linguistic {{Features}} · {{spaCy Usage Documentation}}},
  url = {https://spacy.io/usage/linguistic-features#entity-types},
  urldate = {2024-04-28},
  abstract = {spaCy is a free open-source library for Natural Language Processing in Python. It features NER, POS tagging, dependency parsing, word vectors and more.},
  langid = {english},
  organization = {spaCy},
  file = {/Users/etiennecollin/Documents/Zotero/storage/JQIJV75R/linguistic-features.html}
}

@online{SklearnFeature_extractionText,
  type = {Documentation},
  title = {Sklearn.Feature\_extraction.Text.{{TfidfVectorizer}}},
  url = {https://scikit-learn/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html},
  urldate = {2024-04-28},
  abstract = {Examples using sklearn.feature\_extraction.text.TfidfVectorizer: Biclustering documents with the Spectral Co-clustering algorithm Topic extraction with Non-negative Matrix Factorization and Latent D...},
  langid = {english},
  organization = {scikit-learn},
  file = {/Users/etiennecollin/Documents/Zotero/storage/49YENAPA/sklearn.feature_extraction.text.TfidfVectorizer.html}
}

@online{SklearnFeature_extractionTexta,
  type = {Documentation},
  title = {Sklearn.Feature\_extraction.Text.{{CountVectorizer}}},
  url = {https://scikit-learn/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html},
  urldate = {2024-04-28},
  abstract = {Examples using sklearn.feature\_extraction.text.CountVectorizer: Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation Semi-supervised Classification on a Text Data...},
  langid = {english},
  organization = {scikit-learn},
  file = {/Users/etiennecollin/Documents/Zotero/storage/JJFP3CPF/sklearn.feature_extraction.text.CountVectorizer.html}
}

@online{syrianiAssessingAbilityChatGPT2023,
  title = {Assessing the {{Ability}} of {{ChatGPT}} to {{Screen Articles}} for {{Systematic Reviews}}},
  author = {Syriani, Eugene and David, Istvan and Kumar, Gauransh},
  date = {2023-07-12},
  eprint = {2307.06464},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2307.06464},
  url = {http://arxiv.org/abs/2307.06464},
  urldate = {2024-04-27},
  abstract = {By organizing knowledge within a research field, Systematic Reviews (SR) provide valuable leads to steer research. Evidence suggests that SRs have become first-class artifacts in software engineering. However, the tedious manual effort associated with the screening phase of SRs renders these studies a costly and error-prone endeavor. While screening has traditionally been considered not amenable to automation, the advent of generative AI-driven chatbots, backed with large language models is set to disrupt the field. In this report, we propose an approach to leverage these novel technological developments for automating the screening of SRs. We assess the consistency, classification performance, and generalizability of ChatGPT in screening articles for SRs and compare these figures with those of traditional classifiers used in SR automation. Our results indicate that ChatGPT is a viable option to automate the SR processes, but requires careful considerations from developers when integrating ChatGPT into their SR tools.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Information Retrieval,Computer Science - Software Engineering},
  file = {/Users/etiennecollin/Documents/Zotero/storage/5M2S8U6P/Syriani et al. - 2023 - Assessing the Ability of ChatGPT to Screen Article.pdf;/Users/etiennecollin/Documents/Zotero/storage/5MVQ3D2I/2307.html}
}

@online{UniversalSentenceEncoder2024,
  title = {Universal {{Sentence Encoder}} | {{TensorFlow Hub}}},
  date = {2024-03-10},
  url = {https://www.tensorflow.org/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder},
  urldate = {2024-04-28},
  langid = {english},
  organization = {TensorFlow},
  file = {/Users/etiennecollin/Documents/Zotero/storage/9D3B78T9/semantic_similarity_with_tf_hub_universal_encoder.html}
}

@online{wangGLUEMultiTaskBenchmark2019,
  title = {{{GLUE}}: {{A Multi-Task Benchmark}} and {{Analysis Platform}} for {{Natural Language Understanding}}},
  shorttitle = {{{GLUE}}},
  author = {Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},
  date = {2019-02-22},
  eprint = {1804.07461},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1804.07461},
  url = {http://arxiv.org/abs/1804.07461},
  urldate = {2024-04-28},
  abstract = {For natural language understanding (NLU) technology to be maximally useful, both practically and as a scientific object of study, it must be general: it must be able to process language in a way that is not exclusively tailored to any one specific task or dataset. In pursuit of this objective, we introduce the General Language Understanding Evaluation benchmark (GLUE), a tool for evaluating and analyzing the performance of models across a diverse range of existing NLU tasks. GLUE is model-agnostic, but it incentivizes sharing knowledge across tasks because certain tasks have very limited training data. We further provide a hand-crafted diagnostic test suite that enables detailed linguistic analysis of NLU models. We evaluate baselines based on current methods for multi-task and transfer learning and find that they do not immediately give substantial improvements over the aggregate performance of training a separate model per task, indicating room for improvement in developing general and robust NLU systems.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/etiennecollin/Documents/Zotero/storage/BVCHREV2/Wang et al. - 2019 - GLUE A Multi-Task Benchmark and Analysis Platform.pdf;/Users/etiennecollin/Documents/Zotero/storage/BI983PV3/1804.html}
}
